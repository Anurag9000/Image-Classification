project_name: "Garbage_Classification_Edge_v1"
experiment_name: "Distill_ResNetSwin_to_MobileNet"

# Data Config (Shared)
dataset:
  root_dirs:
    - "d:/Done,Toreview/Image Classification/data"
  json_path: "d:/Done,Toreview/Image Classification/data/Dataset_Final_Aug/dataset_aug_metadata.json"
  batch_size: 8   # Reduced to 8 to prevent OOM on 6GB GPU
  num_workers: 4  # Reduced workers to save CPU RAM overhead
  val_split: 0.1
  test_split: 0.1

# -------------------------------------------------------------------------
# Phase 1 & 2: The TEACHER (Big "Large Ass" Model)
# These settings control the SupCon & ArcFace training of the Teacher.
# -------------------------------------------------------------------------
backbone: 
  cnn_model: "resnet50"
  vit_model: "swin_tiny_patch4_window7_224"
  pretrained: true
embedding_size: 512
num_classes: 6

supcon:
  enabled: true
supcon:
  enabled: true
  epochs: 100 # Exhaustive pretraining on entire dataset
  batch_size: 8 # Drastically reduced for 6GB GPU (OOM at 32)

arcface:
  enabled: true
  epochs: 20
  lr: 1.0e-4
  snapshot_dir: "./snapshots_teacher" # Save Teacher here
  early_stopping_patience: 5

# -------------------------------------------------------------------------
# Phase 3: The STUDENT (Tiny Edge Model)
# The pipeline will load the BEST Teacher from Phase 2, and train THIS config.
# -------------------------------------------------------------------------
distill:
  enabled: true
  epochs: 30
  distill_weight: 0.5 # 50% learn from Teacher, 50% learn from Hard Labels
  temperature: 3.0    # Softer probability distribution for better transfer
  
  # Path to the Teacher we just trained (Pipeline defaults to this, but explicit is good)
  teacher_backbone_path: "./snapshots_teacher/best_model.pth"
  # We don't necessarily need the teacher head if using feature distillation, but for logits we do.
  # The code relies on finding the matching head for the backbone.
  
  # DEFINITION OF THE STUDENT (Raspberry Pi Friendly!)
  backbone:
    cnn_model: "mobilenetv3_large_100" # fast, lightweight
    vit_model: null                    # No transformer for edge speed
    pretrained: true
    fusion_dim: 1280                   # MobileNet output dim (auto-handled usually, but good to note)
  
  log_csv: "./logs/distill_edge_metrics.csv"
  snapshot_dir: "./snapshots_edge_student"
  early_stopping_patience: 10
